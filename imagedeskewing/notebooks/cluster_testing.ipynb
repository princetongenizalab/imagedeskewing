{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f77a7b7c-9e7a-4237-a753-319167c398d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from run import deskew_image\n",
    "\n",
    "from utils.image import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8e67764-87ae-44a3-8c01-d1ef77054782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_images(directory, extension):\n",
    "    \"\"\"\n",
    "    Returns the abs path to all files with a specified extension in a parent directory.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    directory : str\n",
    "        The parent directory to search for the files.\n",
    "    extension : str\n",
    "        The extension of the files to be found.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    images : list\n",
    "        The list of absolute paths to the found files.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(extension):\n",
    "                file_path = os.path.join(root, file)\n",
    "                images.append(file_path)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76c8f626-c645-4cd9-ab15-d28ad6c0208c",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = find_images(\"/scratch/gpfs/RUSTOW/htr_deskewing_image_dataset/NEED_DESKEWING\", \".tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e02f027-3d69-4f87-b5b4-806f8ad9130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from deskew import determine_skew\n",
    "\n",
    "# from jdeskew.estimator import get_angle\n",
    "\n",
    "\n",
    "\n",
    "def calculate_skew_angle(image: np.ndarray) -> float:\n",
    "    \"\"\"Calculate the skew angle of an image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.ndarray\n",
    "        The image data in RGB format.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The skew angle of the image in degrees where an angle > 0 is a counter-clockwise rotation and an angle < 0 is a\n",
    "        clockwise rotation.\n",
    "    \"\"\"\n",
    "    return determine_skew(image, min_deviation=0.025, num_peaks=100)\n",
    "    # return get_angle(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f75b9e17-87f5-4415-84e1-8653f31ff8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from bounding_box_generator import BoundingBoxGenerator\n",
    "from instance_segmentation_generator import InstanceSegmentationGenerator\n",
    "from utils.image import Image\n",
    "# from document_skew_estimator import calculate_skew_angle\n",
    "from skimage.io import imsave\n",
    "\n",
    "def deskew_image(image_path: str, output_path: str):\n",
    "    \"\"\"Deskew an image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_path : str\n",
    "        The path to the image file to be deskewed.\n",
    "    output_path : str\n",
    "        The path to the output image file.\n",
    "    \"\"\"\n",
    "    image = Image(image_path)\n",
    "\n",
    "    #### TEMPORARY CODE ####\n",
    "    grounding_dino_config_path = \"/scratch/gpfs/eh0560/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\"\n",
    "    grounding_dino_weight_path = \"/scratch/gpfs/eh0560/imagedeskewing/models/grounding_dino_models/groundingdino_swint_ogc.pth\"\n",
    "\n",
    "    sam_checkpoint_path = \"../../models/sam_models/sam_vit_h_4b8939.pth\"\n",
    "    model_type = \"vit_h\"\n",
    "\n",
    "    text_prompt = \"old brown paper\"\n",
    "    box_threshold = 0.50\n",
    "    text_threshold = 0.25\n",
    "    ########################\n",
    "\n",
    "    bbg = BoundingBoxGenerator(grounding_dino_config_path, grounding_dino_weight_path)\n",
    "    detections = bbg.find_objects(image.as_array(), text_prompt, box_threshold, text_threshold)\n",
    "\n",
    "    isg = InstanceSegmentationGenerator(model_type, sam_checkpoint_path)\n",
    "    detections.mask = isg.segment_objects(image.as_array(), detections.xyxy)\n",
    "\n",
    "    # Flattening all the masks to a single mask.\n",
    "    mask = np.any(detections.mask, axis=0)\n",
    "\n",
    "    # Computing the smallest bounding box that contains all the masks.\n",
    "    x0 = int(detections.xyxy[:, 0].min())\n",
    "    y0 = int(detections.xyxy[:, 1].min())\n",
    "    x1 = int(detections.xyxy[:, 2].max())\n",
    "    y1 = int(detections.xyxy[:, 3].max())\n",
    "\n",
    "    # Adding padding so the image is not cropped too tightly.\n",
    "    # Found that this improves the accuracy of the skew angle estimation.\n",
    "    padding = -10\n",
    "    x0 = max(0, x0 - padding)\n",
    "    y0 = max(0, y0 - padding)\n",
    "    x1 = min(image.get_width(), x1 + padding)\n",
    "    y1 = min(image.get_height(), y1 + padding)\n",
    "\n",
    "    cropped_image = image.as_array()[y0:y1, x0:x1]\n",
    "\n",
    "    skew_angle = calculate_skew_angle(cropped_image)\n",
    "    print(f\"angle = {skew_angle}\")\n",
    "    imsave(output_path, image.rotated(skew_angle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5b62ef64-18df-4d29-be3d-207dd50f09d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation minimum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdeskew_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./tmp.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./tmp.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[30], line 44\u001b[0m, in \u001b[0;36mdeskew_image\u001b[0;34m(image_path, output_path)\u001b[0m\n\u001b[1;32m     41\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39many(detections\u001b[38;5;241m.\u001b[39mmask, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Computing the smallest bounding box that contains all the masks.\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m x0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[43mdetections\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxyxy\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     45\u001b[0m y0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(detections\u001b[38;5;241m.\u001b[39mxyxy[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmin())\n\u001b[1;32m     46\u001b[0m x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(detections\u001b[38;5;241m.\u001b[39mxyxy[:, \u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mmax())\n",
      "File \u001b[0;32m~/.conda/envs/torch_env/lib/python3.9/site-packages/numpy/core/_methods.py:45\u001b[0m, in \u001b[0;36m_amin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_amin\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     44\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_minimum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation minimum which has no identity"
     ]
    }
   ],
   "source": [
    "deskew_image(images[57], \"./tmp.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab64bb1c-f69a-43f5-9b1c-e6d532fcb5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image(\"./tmp.jpg\")\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))  # specify the figure size in inches\n",
    "plt.imshow(img.as_array())\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ce8662-d0b4-4056-bd1c-e34e63b57bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env [~/.conda/envs/torch_env/]",
   "language": "python",
   "name": "conda_torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
