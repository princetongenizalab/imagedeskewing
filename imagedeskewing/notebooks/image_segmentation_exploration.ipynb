{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatically Generating Document Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import colorsys\n",
    "import random\n",
    "import os\n",
    "\n",
    "from segment_anything import SamAutomaticMaskGenerator, sam_model_registry\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sam_checkpoint = \"../../models/sam_models/sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "_ = sam.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generate_random_color(hue):\n",
    "    \"\"\"\n",
    "    Generate a random pastel color using the golden ratio.\n",
    "\n",
    "    This function takes an initial hue, increments it by the golden ratio conjugate, \n",
    "    and generates a new color in the HSL color space.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    hue : float\n",
    "        The initial hue value for generating the color. It should be a value in the range [0, 1).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    hue : float\n",
    "        The updated hue value.\n",
    "    color : tuple\n",
    "        The generated pastel color in the RGB color space, represented as a tuple of three floats in the range [0, 1).\n",
    "    \"\"\"\n",
    "    golden_ratio_conjugate = 0.618033988749895\n",
    "    hue += golden_ratio_conjugate\n",
    "    hue %= 1\n",
    "    \n",
    "    h, s, l = hue, 0.5, 0.8\n",
    "\n",
    "    return hue, colorsys.hls_to_rgb(h, l, s)\n",
    "\n",
    "\n",
    "def show_anns(anns, alpha=0.5, mask_upscale_factor=1.0):\n",
    "    \"\"\"\n",
    "    Visualize annotations with different colors on a plot.\n",
    "\n",
    "    This function sorts the provided annotations by area in descending order, then visualizes \n",
    "    each annotation with a different color on the current plot.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    anns : list\n",
    "        A list of annotation dictionaries. Each dictionary should have a 'segmentation' key and an 'area' key. \n",
    "        The value of 'segmentation' should be a numpy array representing the mask of the annotation, and the \n",
    "        value of 'area' should be a float representing the area of the annotation.\n",
    "    alpha : float, optional\n",
    "        The transparency level for the colors, represented as a float in the range [0, 1]. The default is 0.5.\n",
    "    mask_upscale_factor : float, optional\n",
    "        The scale factor to increase the mask size by. The default is 1.0 (i.e. no scaling).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    sorted_anns = sorted(anns, key=(lambda x: x[\"area\"]), reverse=True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(False)\n",
    "    \n",
    "    width = int(sorted_anns[0][\"segmentation\"].shape[0] * mask_upscale_factor)\n",
    "    height = int(sorted_anns[0][\"segmentation\"].shape[1] * mask_upscale_factor)\n",
    "\n",
    "    img = np.ones((width, height, 4))\n",
    "    img[:,:,3] = 0\n",
    "    \n",
    "    hue = random.random()\n",
    "    for ann in sorted_anns:\n",
    "        if (mask_upscale_factor != 1.0):\n",
    "            m = ann[\"segmentation\"]\n",
    "            m = cv2.resize(m.astype(np.uint8), (height, width), cv2.INTER_NEAREST) > 0\n",
    "        else:\n",
    "            m = ann[\"segmentation\"]\n",
    "        hue, rgb_color = generate_random_color(hue)\n",
    "        color_mask = np.concatenate([rgb_color, [alpha]])\n",
    "        img[m] = color_mask\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Image Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    \"\"\"\n",
    "    Load an image from a given path, convert it to RGB.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_path : str\n",
    "        A string representing the path of the image file to be loaded.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    resized_image : ndarray\n",
    "        An RGB image.\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "       \n",
    "    return image\n",
    "\n",
    "\n",
    "def preprocess_image(image, kernel_size=1, downscale_factor=1.0):\n",
    "    \"\"\"\n",
    "    Apply Gaussian blur to the given image and resize it to `1/downscale_factor` times the width and height\n",
    "    of the original size.\n",
    "\n",
    "    This function applies a Gaussian blur to the image with a kernel size of (`kernel_size`, `kernel_size`) \n",
    "    and resizes it to `1/rescale_factor` of the original size. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : ndarray\n",
    "        An RGB image.\n",
    "    kernel_size : int, optional\n",
    "        The size of the gaussian blur kernel to apply to the image.\n",
    "    downscale_factor : float, optional\n",
    "        The scale factor to reduce each side of the image by. For exampe, a\n",
    "        `downscale_factor` of 2.0 would decrease each size by a factor of 2.0. \n",
    "        Defaults to 1.0\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pre_processed_image : ndarray\n",
    "        The resized image after applying Gaussian blur with a kernel size of (kernel_size, kernel_size).\n",
    "    \"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    new_height = int(height / downscale_factor)\n",
    "    new_width = int(width / downscale_factor)\n",
    "    resized_image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    blurred_image = cv2.GaussianBlur(resized_image, (kernel_size, kernel_size), 0)\n",
    "    pre_processed_image = blurred_image\n",
    "    \n",
    "    return pre_processed_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def show_image_masks(image, masks, alpha=0.7, mask_upscale_factor=1.0):\n",
    "    \"\"\"\n",
    "    Display an image overlaid with masks.\n",
    "\n",
    "    This function displays a given image in a new figure with given masks overlaid on it.\n",
    "    The masks are visualized using different colors with a set transparency level.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : ndarray\n",
    "        The base image to be displayed. This should be a numpy array of shape \n",
    "        (height, width, 3) and the values should be in the range [0, 1] for floats or [0, 255] for integers.\n",
    "    masks : list\n",
    "        A list of annotation dictionaries. Each dictionary should have a 'segmentation' key and \n",
    "        an 'area' key. The value of 'segmentation' should be a numpy array representing the mask \n",
    "        of the annotation, and the value of 'area' should be a float representing the area of the annotation.\n",
    "    alpha : float, optional\n",
    "        The alpha (transparency) value to display the masks with over the image. Defaults to 0.7\n",
    "    mask_upscale_factor : float, optional\n",
    "        The scale factor to increase the mask size by. The default is 1.0 (i.e. no scaling).\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.imshow(image)\n",
    "    show_anns(masks, alpha=alpha, mask_upscale_factor=mask_upscale_factor)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generate_and_show_masks_from_image_path(image_path, sam_mask_generator, blur_kernel_size, processed_image_downscale_factor):\n",
    "    \"\"\"\n",
    "    Generate and display masks for a given image using a \n",
    "    specified mask generator. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_path : str\n",
    "        A string representing the path of the image file to be loaded.\n",
    "    sam_mask_generator : object\n",
    "        An instance of a mask generator class.\n",
    "    blur_kernel_size : int\n",
    "        Size of the kernel to apply blur with.\n",
    "    processed_image_downscale_factor : float\n",
    "        How much to downscale the image passed to the NN.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    image = load_image(image_path)\n",
    "    processed_image = preprocess_image(image, kernel_size=blur_kernel_size, downscale_factor=processed_image_downscale_factor)\n",
    "    \n",
    "    masks = sam_mask_generator.generate(processed_image)\n",
    "    \n",
    "    show_image_masks(image, masks, mask_upscale_factor=processed_image_downscale_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# tuning settings\n",
    "mask_generator = SamAutomaticMaskGenerator(\n",
    "    model=sam,\n",
    "    points_per_side=8,\n",
    "    points_per_batch=64,\n",
    "    pred_iou_thresh=0.98,\n",
    "    stability_score_thresh=0.98,\n",
    "    min_mask_region_area=128 * 128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pth = \"/projects/RUSTOW/htr_deskewing_image_dataset/needs_deskewing/ENA 1178/000046/ENA_1178_046_r.tif\"\n",
    "generate_and_show_masks_from_image_path(pth, mask_generator, 1, 2.0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env [~/.conda/envs/torch-env/]",
   "language": "python",
   "name": "conda_torch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
