{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9095f6c-825a-41ae-82bf-ee9e272d0869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bounding_box_generator import BoundingBoxGenerator\n",
    "from instance_segmentation_generator import InstanceSegmentationGenerator\n",
    "from utils.image import Image\n",
    "from skimage.io import imsave\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from deskew import determine_skew\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e05f61d8-7052-4ccc-b2d1-edc630f78da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_images(directory, extension):\n",
    "    \"\"\"\n",
    "    Returns the abs path to all files with a specified extension in a parent directory.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    directory : str\n",
    "        The parent directory to search for the files.\n",
    "    extension : str\n",
    "        The extension of the files to be found.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    images : list\n",
    "        The list of absolute paths to the found files.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(extension):\n",
    "                file_path = os.path.join(root, file)\n",
    "                images.append(file_path)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cf44417-896c-48d2-a089-be7b02960144",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = find_images(\"/scratch/gpfs/RUSTOW/htr_deskewing_image_dataset\", \".tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb4d853b-1db5-4f67-be3a-6f3c6264e518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_skew_angle(image: np.ndarray) -> float:\n",
    "    \"\"\"Calculate the skew angle of an image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.ndarray\n",
    "        The image data in RGB format.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The skew angle of the image in degrees where an angle > 0 is a counter-clockwise rotation and an angle < 0 is a\n",
    "        clockwise rotation.\n",
    "    \"\"\"\n",
    "    return determine_skew(image, min_deviation=0.025, num_peaks=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfb74df3-9781-49e0-823b-f07812e03dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eh0560/.conda/envs/torch_env/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "grounding_dino_config_path = \"/scratch/gpfs/eh0560/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\"\n",
    "grounding_dino_weight_path = \"/scratch/gpfs/eh0560/imagedeskewing/models/grounding_dino_models/groundingdino_swint_ogc.pth\"\n",
    "\n",
    "sam_checkpoint_path = \"../../models/sam_models/sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "\n",
    "\n",
    "bbg = BoundingBoxGenerator(grounding_dino_config_path, grounding_dino_weight_path)\n",
    "isg = InstanceSegmentationGenerator(model_type, sam_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b0b13a2-58d0-48a6-8b79-906b3b1ffd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deskew_image(image_path: str, output_path: str, bbg, isg):\n",
    "    image = Image(image_path)\n",
    "\n",
    "    text_prompt = \"old brown paper\"\n",
    "    box_threshold = 0.50\n",
    "    text_threshold = 0.25\n",
    "    \n",
    "    detections = bbg.find_objects(image.as_array(), text_prompt, box_threshold, text_threshold)\n",
    "    detections.mask = isg.segment_objects(image.as_array(), detections.xyxy)\n",
    "    \n",
    "    if(not detections.mask):\n",
    "        imsave(output_path, image.as_array())\n",
    "        return 0\n",
    "    \n",
    "    # Flattening all the masks to a single mask.\n",
    "    mask = np.any(detections.mask, axis=0)\n",
    "    \n",
    "    print(mask)\n",
    "\n",
    "    # Computing the smallest bounding box that contains all the masks.\n",
    "    x0 = int(detections.xyxy[:, 0].min())\n",
    "    y0 = int(detections.xyxy[:, 1].min())\n",
    "    x1 = int(detections.xyxy[:, 2].max())\n",
    "    y1 = int(detections.xyxy[:, 3].max())\n",
    "\n",
    "    # Adding padding so the image is not cropped too tightly.\n",
    "    # Found that this improves the accuracy of the skew angle estimation.\n",
    "    padding = 20\n",
    "    x0 = max(0, x0 - padding)\n",
    "    y0 = max(0, y0 - padding)\n",
    "    x1 = min(image.get_width(), x1 + padding)\n",
    "    y1 = min(image.get_height(), y1 + padding)\n",
    "\n",
    "    cropped_image = image.as_array()[y0:y1, x0:x1]\n",
    "\n",
    "    skew_angle = calculate_skew_angle(cropped_image)\n",
    "\n",
    "    imsave(output_path, image.rotated(skew_angle))\n",
    "    \n",
    "    return skew_angle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88b4a6bf-d8a1-4ab1-9587-0e14f9b0fbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = \"/scratch/gpfs/RUSTOW/deskewed_htr_dataset/\"\n",
    "output_paths = []\n",
    "for image_path in images:\n",
    "    output_path = output_directory + image_path.replace(\"/scratch/gpfs/RUSTOW/htr_deskewing_image_dataset/\", \"\", 1)\n",
    "    output_path = output_path.split(\".tif\")[0] + \".jpg\"\n",
    "    output_paths.append(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2be1132a-b493-4ffb-aa9b-3d53be57c5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 23/892 [11:39<7:20:41, 30.43s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation minimum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(dir_name):\n\u001b[1;32m      5\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(dir_name)\n\u001b[0;32m----> 6\u001b[0m angle \u001b[38;5;241m=\u001b[39m \u001b[43mdeskew_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43misg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m angles[input_image_path] \u001b[38;5;241m=\u001b[39m angle\n",
      "Cell \u001b[0;32mIn[6], line 15\u001b[0m, in \u001b[0;36mdeskew_image\u001b[0;34m(image_path, output_path, bbg, isg)\u001b[0m\n\u001b[1;32m     12\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39many(detections\u001b[38;5;241m.\u001b[39mmask, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Computing the smallest bounding box that contains all the masks.\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m x0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[43mdetections\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxyxy\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     16\u001b[0m y0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(detections\u001b[38;5;241m.\u001b[39mxyxy[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmin())\n\u001b[1;32m     17\u001b[0m x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(detections\u001b[38;5;241m.\u001b[39mxyxy[:, \u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mmax())\n",
      "File \u001b[0;32m~/.conda/envs/torch_env/lib/python3.9/site-packages/numpy/core/_methods.py:45\u001b[0m, in \u001b[0;36m_amin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_amin\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     44\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_minimum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation minimum which has no identity"
     ]
    }
   ],
   "source": [
    "angles = {}\n",
    "for input_image_path, output_image_path in tqdm(zip(images, output_paths), total=len(images)):\n",
    "    dir_name = os.path.dirname(output_image_path)\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "    angle = deskew_image(input_image_path, output_image_path, bbg, isg)\n",
    "    angles[input_image_path] = angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f8e789",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(angles)\n",
    "df.to_csv(\"angles.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env [~/.conda/envs/torch_env/]",
   "language": "python",
   "name": "conda_torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
